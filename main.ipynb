{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# MICCAI2021 Contest : GAMMA Task 3\n",
    "\n",
    "> 视杯视盘分割\n",
    "\n",
    "项目主要参考了第五名之前开源的方案：\n",
    "\n",
    "\t主要思路是将图片目标位置裁剪出来，随后填补到需要的分辨率，而不是直接使用插值算法，减少了噪声的引入。\n",
    "   \n",
    "   此外后处理的引入也有效提高了模型的表现。\n",
    "   \n",
    "   在此基础上重新进行数据划分，调整模型参数，进行二次训练，就能得到更好的效果。\n",
    "    \n",
    "\n",
    "改动的地方在：\n",
    "* ：重新分割训练集和验证集，对生成的模型进行二次训练\n",
    "* ：加入垂直翻转对数据进行进一步增强\n",
    "* ：初次训练时分辨率为1024 * 1024，二次训练时分辨率为512 * 512 增强模型泛化能力 \n",
    "* ：调整后处理函数中的填补参数\n",
    "\n",
    "尝试过的无效改进：\n",
    "* ：修改模型主干网络\n",
    "* ：将提交的最好结果作为伪标签加入训练集\n",
    "* ：深监督和损失函数的修改\n",
    "\n",
    "# 参考：\n",
    "> [1] <https://aistudio.baidu.com/aistudio/projectdetail/2071742>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 0、数据解压及项目准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "# 数据集解压\r\n",
    "! mkdir -p datasets\r\n",
    "! unzip -oq work/Disc_Cup.zip -d datasets\r\n",
    "# 解压测试数据\r\n",
    "! mkdir -p tests\r\n",
    "! unzip -oq work/test.zip -d tests\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 项目准备\r\n",
    "! git clone --depth=1 https://gitee.com/paddlepaddle/PaddleSeg.git  # paddleseg，github太慢\r\n",
    "! pip install -q patta  # patta\r\n",
    "# ! pip install -q albumentations  # 这个可以在终端通过pip3安装\r\n",
    "! pip install imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\r\n",
    "sys.path.append('PaddleSeg')  # paddleseg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1、数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.1 数据信息查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import os\r\n",
    "# import numpy as np\r\n",
    "# from PIL import Image\r\n",
    "\r\n",
    "# 查看大小\r\n",
    "# img_size = []\r\n",
    "# imgs_folder_path = 'datasets/Disc_Cup_Mask'\r\n",
    "# imgs_name = os.listdir(imgs_folder_path)\r\n",
    "# for name in imgs_name:\r\n",
    "#     img_path = os.path.join(imgs_folder_path, name)\r\n",
    "#     img = np.asarray(Image.open(img_path))\r\n",
    "#     img_size.append(img.shape)\r\n",
    "# print(set(img_size))\r\n",
    "# 查看标签数值\r\n",
    "# label = np.asarray(Image.open('datasets/Disc_Cup_Mask/0004.png'))\r\n",
    "# print(set(label.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.2 数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import os\r\n",
    "# # import random\r\n",
    "# from PIL import Image\r\n",
    "\r\n",
    "# # 手动选择了10张特征各异的，评估比较有说服力\r\n",
    "# val_name_list = ['0080.jpg', '0070.jpg', '0006.jpg', '0063.jpg', '0086.jpg', \\\r\n",
    "#                  '0075.jpg', '0096.jpg', '0030.jpg', '0062.jpg', '0081.jpg']\r\n",
    "\r\n",
    "# def create_list(data_path):\r\n",
    "#     image_path = os.path.join(data_path, 'Image')\r\n",
    "#     label_path = os.path.join(data_path, 'Disc_Cup_Mask')\r\n",
    "#     data_names = os.listdir(image_path)\r\n",
    "#     # random.shuffle(data_names)  # 打乱数据\r\n",
    "#     with open(os.path.join(data_path, 'train_list.txt'), 'w') as tf:\r\n",
    "#         with open(os.path.join(data_path, 'val_list.txt'), 'w') as vf:\r\n",
    "#             for idx, data_name in enumerate(data_names):\r\n",
    "#                 img = os.path.join('Image', data_name)\r\n",
    "#                 lab = os.path.join('Disc_Cup_Mask', data_name.replace('jpg', 'png'))\r\n",
    "#                 # if idx % 9 == 0:  # 90%的作为训练集\r\n",
    "#                 if data_name in val_name_list:\r\n",
    "#                     vf.write(img + ' ' + lab + '\\n')\r\n",
    "#                 else:\r\n",
    "#                     tf.write(img + ' ' + lab + '\\n')\r\n",
    "#     print('数据列表生成完成')\r\n",
    "\r\n",
    "# data_path = 'datasets'\r\n",
    "# create_list(data_path)  # 生成数据列表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.3 数据集构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddleseg.transforms as T\r\n",
    "from paddleseg.datasets import Dataset\r\n",
    "\r\n",
    "# 构建训练集\r\n",
    "train_transforms = [\r\n",
    "    T.LocalEqualHist(),  # 自适应局部直方图均衡化\r\n",
    "    T.RandomHorizontalFlip(),  # 水平翻转\r\n",
    "    T.RandomVerticalFlip(), # 垂直翻转\r\n",
    "    T.RandomRotation(im_padding_value=[0, 0, 0]),  # 随机旋转\r\n",
    "    T.Resize(target_size=( 512, 512)),  # 兼顾大小\r\n",
    "    T.Normalize(\r\n",
    "        [0.3883131, 0.25449154, 0.110598095], \r\n",
    "        [0.26274413, 0.1827712, 0.12587263]),  # 标准化\r\n",
    "]\r\n",
    "train_dataset = Dataset(\r\n",
    "    transforms=train_transforms,\r\n",
    "    dataset_root='datasets',\r\n",
    "    num_classes=3,\r\n",
    "    mode='train',\r\n",
    "    train_path='datasets/train_list.txt',\r\n",
    "    separator=' ',\r\n",
    ")\r\n",
    "# 构建验证集\r\n",
    "val_transforms = [\r\n",
    "    T.NormSize(),\r\n",
    "    T.LocalEqualHist(),\r\n",
    "    T.Resize(target_size=(512, 512)),\r\n",
    "    T.Normalize(\r\n",
    "        [0.3883131, 0.25449154, 0.110598095], \r\n",
    "        [0.26274413, 0.1827712, 0.12587263]),    \r\n",
    "]\r\n",
    "val_dataset = Dataset(\r\n",
    "    transforms=val_transforms,\r\n",
    "    dataset_root='datasets',\r\n",
    "    num_classes=3,\r\n",
    "    mode='train',  # 这里用train，不然无法对标签进行NormSize\r\n",
    "    train_path='datasets/val_list.txt',\r\n",
    "    separator=' ',\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.5 均值、方差统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import os\r\n",
    "# import cv2\r\n",
    "# import numpy as np\r\n",
    "# from tqdm import tqdm\r\n",
    " \r\n",
    "# means, stdevs = [], []\r\n",
    "# img_list = []\r\n",
    "# imgs_path = 'vis_aug/img'\r\n",
    "# imgs_name = os.listdir(imgs_path)\r\n",
    "# for name in tqdm(imgs_name):\r\n",
    "#     img = cv2.cvtColor(cv2.imread(os.path.join(imgs_path, name)), cv2.COLOR_BGR2RGB)\r\n",
    "#     img = img[:, :, :, np.newaxis]\r\n",
    "#     img_list.append(img)\r\n",
    "# imgs = np.concatenate(img_list, axis=-1)\r\n",
    "# imgs = imgs.astype(np.float32) / 255.\r\n",
    "# for i in range(3):\r\n",
    "#     pixels = imgs[:, :, i, :].ravel()  # 拉成一行\r\n",
    "#     means.append(np.mean(pixels))\r\n",
    "#     stdevs.append(np.std(pixels))\r\n",
    "# print(means, stdevs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "* [0.3883131, 0.25449154, 0.110598095] \n",
    "* [0.26274413, 0.1827712, 0.12587263]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 二、训练准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1122 21:32:01.907361   450 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W1122 21:32:01.912304   450 device_context.cc:422] device: 0, cuDNN Version: 7.6.\n"
     ]
    }
   ],
   "source": [
    "import paddle\r\n",
    "import paddle.nn as nn\r\n",
    "from paddleseg.models import OCRNet, HRNet_W18\r\n",
    "\r\n",
    "model = OCRNet(\r\n",
    "    backbone=HRNet_W18(),\r\n",
    "    backbone_indices=[0],\r\n",
    "    num_classes=3)\r\n",
    "params = paddle.load('output_ocrnet_hrnet18/best_model/model.pdparams')\r\n",
    "model.set_state_dict(params)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 三、模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddleseg.core import train\r\n",
    "from paddleseg.models.losses import CrossEntropyLoss, DiceLoss, MixedLoss\r\n",
    "\r\n",
    "iters = 5000\r\n",
    "batch_size = 4\r\n",
    "base_lr = 3e-4\r\n",
    "\r\n",
    "lr = paddle.optimizer.lr.CosineAnnealingDecay(base_lr, T_max=int(iters // 1.5))\r\n",
    "optimizer = paddle.optimizer.Adam(\r\n",
    "    learning_rate=lr,\r\n",
    "    parameters=model.parameters(),\r\n",
    "    weight_decay=paddle.regularizer.L2Decay(1e-7),\r\n",
    "    grad_clip=paddle.nn.ClipGradByGlobalNorm(clip_norm=1.0))\r\n",
    "\r\n",
    "losses = {}\r\n",
    "losses['types'] = [MixedLoss([CrossEntropyLoss(), DiceLoss()], [1, 1])] * 2  # 2\r\n",
    "losses['coef'] = [1] * 2  # 2\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "train(\r\n",
    "    model=model,\r\n",
    "    train_dataset=train_dataset,\r\n",
    "    val_dataset=val_dataset,\r\n",
    "    optimizer=optimizer,\r\n",
    "    save_dir='output_ocrnet_hrnet18',\r\n",
    "    iters=iters,\r\n",
    "    batch_size=batch_size,\r\n",
    "    save_interval=int(iters/10),\r\n",
    "    log_iters=200,\r\n",
    "    num_workers=0,\r\n",
    "    losses=losses,\r\n",
    "    use_vdl=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 四、模型预测\n",
    "- 使用了水平翻转的tta\n",
    "- 需要将大小和位置统一回原数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\r\n",
    "from paddleseg.models import OCRNet, HRNet_W18\r\n",
    "import paddleseg.transforms as T\r\n",
    "from paddleseg.core import infer\r\n",
    "import os\r\n",
    "from tqdm import tqdm\r\n",
    "from PIL import Image\r\n",
    "import numpy as np\r\n",
    "import patta as tta\r\n",
    "from mytools import tensor2result, restore\r\n",
    "\r\n",
    "def nn_infer(model, imgs_path, is_tta=True):\r\n",
    "    if not os.path.exists('result'):\r\n",
    "        os.mkdir('result')\r\n",
    "    # 预测结果\r\n",
    "    transforms = T.Compose([\r\n",
    "        T.NormSize(),\r\n",
    "        T.LocalEqualHist(),\r\n",
    "        T.Resize(target_size=(512, 512)),\r\n",
    "        T.Normalize(\r\n",
    "            [0.3883131, 0.25449154, 0.110598095], \r\n",
    "            [0.26274413, 0.1827712, 0.12587263])\r\n",
    "    ])\r\n",
    "    # 循环预测和保存\r\n",
    "    for img_path in tqdm(imgs_path):\r\n",
    "        H, W = np.asarray(Image.open(img_path)).shape[:2]  # 获取原始的H和W\r\n",
    "        img, _ = transforms(img_path)  # 进行数据预处理\r\n",
    "        img = paddle.to_tensor(img[np.newaxis, :])  # C,H,W -> 1,C,H,W\r\n",
    "        # TTA\r\n",
    "        if is_tta == True:\r\n",
    "            tta_pres = paddle.zeros([1, 3,  512, 512])  # 图像大小1024\r\n",
    "            for tta_transform in tta.aliases.hflip_transform ():\r\n",
    "                tta_img = tta_transform.augment_image(img)  # TTA_transforms\r\n",
    "                tta_pre = infer.inference(model, tta_img)  # 预测\r\n",
    "                deaug_pre = tta_transform.deaugment_mask(tta_pre)\r\n",
    "                tta_pres += deaug_pre\r\n",
    "            pre = tta_pres / 2.\r\n",
    "        else:\r\n",
    "            pre = infer.inference(model, img)  # 预测\r\n",
    "        pred = tensor2result(pre)  # 转为颜色对应的array\r\n",
    "        pred = restore(pred, H, W)  # 恢复原始大小\r\n",
    "        pil_img = Image.fromarray(pred)\r\n",
    "        pil_img.save(os.path.join('result', img_path.split('/')[-1].replace('jpg', 'bmp')), 'bmp')\r\n",
    "\r\n",
    "# 网络准备\r\n",
    "\r\n",
    "model_path = 'output_ocrnet_hrnet18/best_model/model.pdparams'\r\n",
    "model = OCRNet(\r\n",
    "    backbone=HRNet_W18(),\r\n",
    "    backbone_indices=[0],\r\n",
    "    num_classes=3)\r\n",
    "params = paddle.load(model_path)\r\n",
    "model.set_state_dict(params)\r\n",
    "\r\n",
    "\r\n",
    "model.eval()\r\n",
    "\r\n",
    "# 预测文件\r\n",
    "# set_path = 'datasets'\r\n",
    "# list_file = 'datasets/val_list.txt'\r\n",
    "# imgs_path = []\r\n",
    "# with open(list_file, 'r') as f:\r\n",
    "#     datas_path = f.readlines()\r\n",
    "#     for data_path in datas_path:\r\n",
    "#         imgs_path.append(os.path.join(set_path, data_path.split(' ')[0].strip()))\r\n",
    "\r\n",
    "test_folder = \"tests\"\r\n",
    "imgs_path = os.listdir(test_folder)\r\n",
    "imgs_path = [os.path.join(test_folder, name) for name in imgs_path]\r\n",
    "# 预测\r\n",
    "nn_infer(model, imgs_path, is_tta=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 五、预测后处理\n",
    "1. 闭运算填充孔洞\n",
    "2. 保留最大联通区，去掉其他小的联通区"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "import numpy as np\r\n",
    "from tqdm import tqdm\r\n",
    "from PIL import Image\r\n",
    "from aftercure import one_package_service\r\n",
    "\r\n",
    "pred_folder = 'result'\r\n",
    "save_folder = 'af_result'\r\n",
    "if not os.path.exists(save_folder):\r\n",
    "    os.mkdir(save_folder)\r\n",
    "imgs_name = os.listdir(pred_folder)\r\n",
    "for name in tqdm(imgs_name):\r\n",
    "    img_path = os.path.join(pred_folder, name)\r\n",
    "    img = np.asarray(Image.open(img_path))\r\n",
    "    result = Image.fromarray(one_package_service(img, k_size=350))\r\n",
    "    result.save(img_path.replace(pred_folder, save_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 六、结果评价\n",
    "Dice系数作为分割结果测评的评价指标：\n",
    "\n",
    "$\\text { Dice }=\\frac{2|X \\cap Y|}{|X|+|Y|}$\n",
    "\n",
    "其中，X代表金标准中分割目标像素点集合，Y代表预测结果中分割目标像素点集合，公式中 |X∩Y| 是X和Y之间的交集，|X|和|Y|分表表示X和Y的元素的个数。\n",
    "此外，我们使用平均绝对误差（Mean Absolute Error）来测量样本视杯视盘分割结果与金标准之间的垂直杯盘比差异。垂直杯盘比有直接的临床相关性，可辅助评估青光眼的进展。求解方式为计算垂直方向上视杯区域和视盘区域最大直径的比值。对于任务三，最终的评分综合了视杯分割结果Dice系数、视盘分割结果Dice系数，和垂直杯盘比数值的MAE：\n",
    "\n",
    "$\\text { Score }_{\\text {task } 3}=0.25 * \\text { Dice }_{\\text {cup }}+0.35 * \\text { Dice }_{d i s c}+0.04 * \\frac{1}{M A E+0.1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 解压\r\n",
    "! zip -q -r result.zip af_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "> 最终得分为: 8.20684"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
